<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Risk-Aware Safe RL for Autonomous Driving | Zhuoren Li </title> <meta name="author" content="Zhuoren Li"> <meta name="description" content="Enhancing the safety performance of RL-based motion planning by prior-knowledge designed safety constraints. (From Sept 2022 to now)"> <meta name="keywords" content="Zhuoren Li ÊùéÊãô‰∫∫"> <link href="https://fonts.googleapis.com/css?family=Lato%3A300%2C300italic%2C400%2C400italic%2C700%2C700italic&amp;display=swap" rel="stylesheet" nonce="V-Zqrmglytjh-kKelnfQpQ"> <link href="https://fonts.googleapis.com/css?family=Google+Sans:400,500|Roboto:300,400,500,700|Source+Code+Pro:400,700&amp;display=swap" rel="stylesheet" nonce="V-Zqrmglytjh-kKelnfQpQ"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://simengli1998.github.io/researches/safe-reinforcement-learning-for-autonomous-driving/"> <script src="/assets/js/theme.js?9129f6de4034f4a11893cd54bb22df5e"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap" style="width:100%;justify-content: space-between;"> <li class="nav-item"><a class="nav-link" href="/#-about">Home</a></li> <li class="nav-item"><a class="nav-link" href="/#-news">News</a></li> <li class="nav-item"><a class="nav-link" href="/#-research-experiences">Research Experiences</a></li> <li class="nav-item"><a class="nav-link" href="/#-publications">Publications</a></li> <li class="nav-item"><a class="nav-link" href="/#-project-experiences">Projects</a></li> <li class="nav-item"><a class="nav-link" href="/#-honors-and-awards">Honors and Awards</a></li> <li class="nav-item"><a class="nav-link" href="/#-academic-services">Academic Services </a></li> <li class="nav-item"><a class="nav-link" href="/assets/pdf/Zhuoren_Li_CV.pdf">CV</a></li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post "> <header class="post-header"> <h1 class="post-title">Risk-Aware Safe RL for Autonomous Driving</h1> <p class="post-description">Enhancing the safety performance of RL-based motion planning by prior-knowledge designed safety constraints. (From Sept 2022 to now)</p> </header> <article> <h3 id="uncertainty-aware-safe-rl-for-safety-critical-decision-and-control-with-high-order-cbf"><strong>Uncertainty-aware safe RL for safety-critical decision and control with high-order CBF</strong></h3> <p>Collaborating student: <em>Ran Yu, 1st-year Gruaduate Student</em>.</p> <h4 id="motivation"><strong>Motivation</strong></h4> <p>CBF-RL has become popular in the field of safe RL control in recent years. However, due to the high relative degree between the standard CBF and the underlying system control inputs, the safety can be compromised due to the inability to constrain the higher-order dynamics resulting in transient transgressions of the lower-order constraints.</p> <p>Additionally, cognitive limitations and environmental randomness can lead to unreliable decisions in safety-critical scenarios. The estimated uncertainty of RL policy can provide a design basis for the dynamic adjustment of CBF constraints.</p> <p><img src="/assets/img/researches/safe/HOCBF-RLframe.png" alt="png"></p> <p>Therefore, this work generates a risk-averse policy by constructing a risk-aware ensemble distributional RL, while estimating uncertainty to quantify the policy‚Äôs reliability. A high-order control barrier function (HOCBF) is employed as a safety filter to minimize intervention policy while dynamically enhancing constraints based on uncertainty.</p> <h4 id="highlights"><strong>Highlights</strong></h4> <ul> <li>Propose a risk-aware distributional RL ensemble architecture that combines the original and Fixed Prior Networks (FPN) to build the critic. It quantifies tail risk in the reward distribution and generates a risk-averse policy, while jointly estimating epistemic uncertainty and aleatoric uncertainty for dual uncertainty-driven decision-making.</li> <li>A high-order control barrier function (HOCBF) is constructed, which ensures safety using only relative distance. Moreover, HOCBF incorporates JU to dynamically adjust safety constraints, balancing safety and traffic efficiency.</li> </ul> <h4 id="some-results"><strong>Some Results</strong></h4> <p><img src="/assets/img/researches/safe/HOCBFresult.png" alt="png"> <img src="/assets/img/researches/safe/HOCBFcase.png" alt="png"></p> <p>More details can be found in our recent paper ‚ÄúUncertainty-Aware Safety-Critical Decision and Control for Autonomous Vehicles at Unsignalized Intersections.‚Äù (under review) <a href="/assets/pdf/paper/HOCBF-RL.pdf">PDF</a></p> <h3 id="safe-drl-with-risk-evaluation-and-dangerous-momry-enhancement"><strong>Safe DRL with risk evaluation and dangerous momry enhancement</strong></h3> <p>Collaborating student: <em>Guizhe Jin, 2st-year Gruaduate Student</em>.</p> <h4 id="motivation-1"><strong>Motivation</strong></h4> <p>Evaluating the anticipated safety risk in the long time domain can provide better safety guidance for driving behavior decisions. Explicitly constructing future trajectories corresponding to RL actions coudld make it conveniently combined with risk evaluation.</p> <p><img src="/assets/img/researches/safe/featured.png" alt="png"></p> <p>Proposeing a safety enhanced deep reinforcement learning for autonomous motion planning in lane-changing maneuver. The goal of this work is to design a DRL motion planner, which dares to make mistakes to learn the safe driving policy faster and better.</p> <h4 id="highlights-1"><strong>Highlights</strong></h4> <ul> <li>Evaluate the future motion risk by projecting DRL behavior action into the feasible trajectory, while sorrunding vehicles‚Äô trajecotires are obtained from the prediction module.</li> <li>Dangerous action will be prevented and the dangerous virtual experiences are recoreded to gain various valuable experience data.</li> <li>Dangerous experiences are sampled with priority weight according their anticipated risk, enabling DRL agnet to learn a safer policy.</li> </ul> <h4 id="some-results-1"><strong>Some Results</strong></h4> <p><img src="/assets/img/researches/safe/traincurve.png" alt="png"> <img src="/assets/img/researches/safe/testTR.png" alt="png"></p> <p><img src="/assets/img/researches/safe/highenvgif.gif" alt="png"> Proposing safety enhanced DRL approach could improve the driving performance, espeacially in safety metrics such as reducing collision rate, anticipated risk, etc.</p> <p>More details can be found in our recent paper ‚ÄúSafety Enhanced Reinforcement Learning for Autonomous Driving: Dare to Make Mistakes to Learn Faster and Better‚Äù. (under review, it will come soon) and ‚ÄúSafe Reinforcement Learning of Lane Change Decision Making with Risk-Fused Constraint‚Äù. <a href="/assets/pdf/paper/Safe_Reinforcement_Learning_of_Lane_Change_Decision_Making_with_Risk-Fused_Constraint.pdf">PDF</a>, <a href="https://ieeexplore.ieee.org/document/10422331" rel="external nofollow noopener" target="_blank">DOI</a>.</p> <h3 id="risk-awre-rl-based-on-safe-critic-and-iterative-action-correction"><strong>Risk-awre RL based on Safe Critic and Iterative Action Correction</strong></h3> <p>Collaborating student: <em>Ran Yu, 1st-year Gruaduate Student</em>.</p> <h4 id="motivation-2"><strong>Motivation</strong></h4> <p>The inability to handle the dynamic changes in the number and permutation of surroundings traffic participants may make it difficult for AVs to identify potential risks and adopt unsafe strategies. Moreover, the complex information at these intersections requires the AV to identify pivotal data to ascertain the timing of passage.</p> <p><img src="/assets/img/researches/safe/featured2.png" alt="png"></p> <p>A risk-aware RL approach is proposed to improve safety and efficiency for driving through intersection.</p> <h4 id="highlights-2"><strong>Highlights</strong></h4> <ul> <li>Safe critics are constructed to evaluate driving risk and work in conjunction with the reward critic to update the actor.</li> <li>A Lagrangian relaxation method is incorporated to generate approximate safe actions, which are projected into a feasible safe region with safety iterative correction by cyclic gradient descent.</li> <li>A Multi-hop and Multi-layer perception mixed Attention Mechanism (MMAM) integrated into the actorcritic network enables the policy to adapt to dynamic traffic and overcome permutation sensitivity challenges, enhancing scene understanding and improving decision-making timing when navigating intersections.</li> </ul> <h4 id="some-results-2"><strong>Some Results</strong></h4> <p>We compare Attention embedded and Risk-aware Soft Actor Critic (ARSAC) to the following baselines: SAC-RS, PPO-RS, which incorporate an auxiliary reward ùê´_ùë†ùëéùëìùëí compared to standard SAC and PPO; SAC-Lag and CPO. The implementation of SAC-Lag and CPO are based on Omnisafe Library. <img src="/assets/img/researches/safe/EAAIresult1.png" alt="png"> <img src="/assets/img/researches/safe/EAAIresult2.png" alt="png"></p> <p>Results indicate that the proposed ARSAC algorithm outperforms or matches all other baseline algorithms across three driving tasks in terms of the final performance. Meanwhile, ablation studies demonstrate the specific role of different modules.</p> <p><img src="/assets/img/researches/safe/EAAIcase1.png" alt="png"> <img src="/assets/img/researches/safe/EAAIcase2.png" alt="png"></p> <p>More details can be found in our recent paper ‚ÄúRisk-Aware Reinforcement Learning for Autonomous Driving: Improving Safety When Driving through Intersection.‚Äù (under review) <a href="/assets/pdf/paper/SRL2024In.pdf">PDF</a></p> <h3 id="current-work"><strong>Current Work</strong></h3> <ul> <li>Combination CBF-based constraints and intrinsic reward optimization to accommodate safety and efficiency objectives.</li> <li>A learnable evaluation module to predict the anticipated risk.</li> </ul> <h3 id="publications"><strong>Publications:</strong></h3> <ol> <li>Uncertainty-Aware Safety-Critical Decision and Control for Autonomous Vehicles at Unsignalized Intersections, Ran Yu, <strong>Zhuoren Li*</strong>, Lu Xiong, Wei Han and Bo Leng, <em>IEEE Intell. Transp. Syst. Conf. (ITSC)</em>, 2025. (accept) <a href="https://arxiv.org/abs/2505.19939" rel="external nofollow noopener" target="_blank">arXiv</a> </li> <li> <a href="https://ieeexplore.ieee.org/document/11130420" rel="external nofollow noopener" target="_blank"><u>Convergent Harmonious Decision: Lane Changing in a more Traffic Friendly Way</u></a>, Ruolin Yang, <strong>Zhuoren Li</strong>, Bo Leng, Lu Xiong and Xin Xia, <em>IEEE Trans. Intell. Transp. Syst.</em>, vol. 26, no. 11, pp. 20334-20347, 2025.</li> <li> <a href="https://cjme.springeropen.com/articles/10.1186/s10033-024-01160-z" rel="external nofollow noopener" target="_blank">Rule-Guidance Reinforcement Learning for Lane Change Decision-making: A Risk Assessment Approach</a>, Lu Xiong, <strong>Zhuoren Li</strong>, Danyang Zhong, Puhang Xu and Chen Tang, <em>Chin. J. Mech. Eng.</em> 2025, 38:30.</li> <li> <a href="https://ieeexplore.ieee.org/document/10422331" rel="external nofollow noopener" target="_blank">Safe Reinforcement Learning of Lane Change Decision Making with Risk-Fused Constraint</a>, <strong>Zhuoren Li</strong>, Lu Xiong, Bo Leng, Puhang Xu and Zhiqiang Fu, in <em>Proc. IEEE Intell. Transp. Syst. Conf. (ITSC)</em>, 2023, pp. 1313-1319.</li> </ol> <h3 id="submittedin-progress"><strong>Submitted/In Progress:</strong></h3> <ol> <li>Safety Enhanced Reinforcement Learning for Autonomous Driving: Dare to Make Mistakes to Learn Faster and Better, <strong>Zhuoren Li</strong>, Jia Hu, Bo Leng, Lu Xiong and Puhang Xu, <em>IEEE Trans. Intell. Transp. Syst.</em> (under review, R1)</li> <li> <a href="https://arxiv.org/abs/2505.19939" rel="external nofollow noopener" target="_blank"><u>Uncertainty-Aware Safety-Critical Decision and Control for Autonomous Vehicles at Unsignalized Intersections</u></a>, Ran Yu, <strong>Zhuoren Li*</strong>, Lu Xiong, Wei Han and Bo Leng, <em>IEEE Intell. Transp. Syst. Conf. (ITSC)</em>, 2025. (accept)</li> <li> <a href="https://ieeexplore.ieee.org/document/10422331" rel="external nofollow noopener" target="_blank"><u>Safe Reinforcement Learning of Lane Change Decision Making with Risk-Fused Constraint</u></a>, <strong>Zhuoren Li</strong>, Lu Xiong, Bo Leng, Puhang Xu and Zhiqiang Fu, in <em>Proc. IEEE Intell. Transp. Syst. Conf. (ITSC)</em>, 2023, pp. 1313-1319.</li> </ol> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> ¬© Copyright 2026 Zhuoren Li. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. </div> </footer> <script src="https://code.jquery.com/jquery.min.js" integrity="" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="" integrity="" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/jquery.smooth-scroll.min.js?ee5bd2a00f7ab2db9a6be01703c6b2b0"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?0e7d05625b18475c285fde547d3c8f67"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?version=4.8.0&amp;features=es6" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?601a2d3465e2a52bec38b600518d5f70"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"About",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-research",title:"Research",description:"This section showcases some side research/fun projects that may not directly align with my main research direction, along with ongoing research and projects. Feel free to reach out if you&#39;re interested! \ud83d\udce9",section:"Navigation",handler:()=>{window.location.href="/researches/"}},{id:"nav-awards",title:"Awards",description:"AWARDS, FUNDS and CERTIFICATES",section:"Navigation",handler:()=>{window.location.href="/awards/"}},{id:"nav-life",title:"Life",description:"",section:"Navigation",handler:()=>{window.location.href="/life/"}},{id:"nav-cv",title:"CV",description:"",section:"Navigation",handler:()=>{window.location.href="/assets/pdf/cv.pdf"}},{id:"news-dialogue-with-prof-gabor-from-university-of-michigan",title:"\ud83e\udd1d Dialogue with Prof. Gabor from University of Michigan",description:"It was pleasured to invite Prof. Gabor Orosz from the University of Michigan to Tongji University.",section:"News",handler:()=>{window.location.href="/news/communicate_with_prof_gabor/"}},{id:"news-insightful-exchange-during-iscc-2024",title:"\ud83e\udd1d Insightful Exchange during ISCC 2024",description:"During the ISCC 2024, it was an honor to invite three experts (Prof. Abbas Jamalipour, EIC IEEE TVT, Dr. Jost Bernasch, CEO of Virtual Vehicle Research GmbH, and Dr. Michael Paulweber, Dir. Research &amp; Technology ITS, AVL List GesmbH) to visit the School of Automotive Studies, Tongji University and our TJIIV Lab.",section:"News",handler:()=>{window.location.href="/news/iscc2024/"}},{id:"news-two-presentation-in-itsc-2024-canada",title:"\ud83d\udcac Two Presentation in ITSC 2024, Canada",description:"Our paper \u201cStability Enhanced Hierarchical Reinforcement Learning for Autonomous Driving with Parameterized Trajectory Action\u201d has presented in ITSC 2024.",section:"News",handler:()=>{window.location.href="/news/itsc2024/"}},{id:"news-sae-international-outstanding-technical-paper-award-in-sae-icvs-2024",title:":\ud83c\udf89 SAE International Outstanding Technical Paper Award in SAE ICVS 2024",description:"Our paper &quot;Interaction-aware Deep Reinforcement Learning Approach based on Hybrid Parameterized Action Space for Autonomous Driving&quot; has obtained the Outstanding Technical Paper Award.",section:"News",handler:()=>{window.location.href="/news/icvs2024/"}},{id:"researches-llm-enhanced-rl-for-autonomous-driving",title:"LLM enhanced RL for Autonomous Driving",description:"Enhancing scenario understanding ablility for RL agent using LLM while suppressing the hallucinatory problems. (Dec 2024 - now)",section:"Researches",handler:()=>{window.location.href="/researches/LLM-enhanced-RL/"}},{id:"researches-optimization-based-motion-planning",title:"Optimization-based Motion Planning",description:"Smooth, stable and fast motion planning based on optimization-based approaches. (Sep 2021 - Jun 2023)",section:"Researches",handler:()=>{window.location.href="/researches/optimization-based-motion-planning/"}},{id:"researches-parking-path-planning",title:"Parking Path Planning",description:"Simple and effective parking path planning based on geometric curve and MPC optimization. (Feb 2021 - Aug 2021)",section:"Researches",handler:()=>{window.location.href="/researches/parking-path-planning/"}},{id:"researches-control-granularity-research-of-rl-based-motion-planning",title:"Control Granularity Research of RL-based Motion Planning",description:"using skill primitive and parameterized action with sufficient control granularity for flexible and smooth driving. (Dec 2023 - Mar 2025)",section:"Researches",handler:()=>{window.location.href="/researches/reinforcement-learning-for-smooth-motion-lanning/"}},{id:"researches-risk-aware-safe-rl-for-autonomous-driving",title:"Risk-Aware Safe RL for Autonomous Driving",description:"Enhancing the safety performance of RL-based motion planning by prior-knowledge designed safety constraints. (From Sept 2022 to now)",section:"Researches",handler:()=>{window.location.href="/researches/safe-reinforcement-learning-for-autonomous-driving/"}},{id:"socials-email",title:"Send email",section:"Socials",handler:()=>{window.open("mailto:%31%39%31%31%30%35%35@%74%6F%6E%67%6A%69.%65%64%75.%63%6E","_blank")}},{id:"socials-github",title:"GitHub",section:"Socials",handler:()=>{window.open("https://github.com/ZhuorenLi","_blank")}},{id:"socials-linkedin",title:"LinkedIn",section:"Socials",handler:()=>{window.open("https://www.linkedin.com/in/zhuorenli-patrick","_blank")}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>